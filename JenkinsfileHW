// Pipeline
lock(label: 'adgt_test_harness_boards') {
  // @Library('sdgtt-lib@adgt-test-harness') _ // Not necessary when we turn on global libraries :)
  @Library('sdgtt-lib@fix_iio_not_defined') _
  def dependencies = ["nebula", "libiio", "libiio-py"]
  def hdlBranch = "hdl_2019_r2"
  def linuxBranch = "2019_R2"
  def bootPartitionBranch = "release"
  def jenkins_job_trigger = "-1"
  def firmwareVersion = 'v0.32'
  def bootfile_source = 'artifactory' // options: sftp, artifactory, http, local
  def harness = getGauntlet(dependencies, hdlBranch, linuxBranch, bootPartitionBranch, firmwareVersion, bootfile_source)

  //save what triggered the job
  harness.set_job_trigger(jenkins_job_trigger)

  //udpate repos
  harness.set_env('nebula_repo', 'https://github.com/sdgtt/nebula.git')
  harness.set_env('nebula_branch', 'do_not_load_system_uart_if_zcu102')
  // harness.set_env('nebula_branch','dev')
  harness.set_env('libiio_branch', 'v0.21')
  harness.set_env('telemetry_repo', 'https://github.com/kimpaller/telemetry.git')
  harness.set_env('telemetry_branch', 'master')

  //update first the agent with the required deps
  harness.update_agents()

  //update nebula config
  def jobs = [: ]
  for (agent in harness.gauntEnv.agents_online) {
    println('Agent: ' + agent)
    def agent_name = agent
    jobs[agent_name] = {
      node(agent_name) {
        stage('Update Nebula Config') {
          sh 'if [ -d "nebula-config" ]; then rm -Rf nebula-config; fi'
          sh 'git clone -b master https://github.com/kimpaller/nebula-config.git'
          cmd = 'sudo mv nebula-config/' + agent_name + ' /etc/default/nebula'
          sh cmd
        }
        stage('Clean up residue docker containers') {
          sh 'sudo docker ps -q -f status=exited | xargs --no-run-if-empty sudo docker rm'
        }
      }
    }
  }

  stage('Configure Agents') {
    parallel jobs
  }

  //set other test parameters
  harness.set_nebula_debug(true)
  harness.set_enable_docker(true)
  harness.set_send_telemetry(false)
  harness.set_docker_host_mode(false)
  harness.set_enable_resource_queuing(true)
  harness.set_elastic_server('192.168.10.1')
  harness.set_required_hardware([
    "zynq-zed-adv7511-ad9361-fmcomms2-3",
    "zynq-zc702-adv7511-ad9361-fmcomms2-3",
    "zynq-zc706-adv7511-ad9361-fmcomms2-3",
    "zynq-zc702-adv7511-ad9361-fmcomms5",
    "zynq-zc706-adv7511-ad9361-fmcomms5"
  ])
  harness.set_docker_args([])
  harness.set_nebula_local_fs_source_root("artifactory.analog.com")

  // Set stages (stages are run sequentially on agents)
  harness.add_stage(harness.stage_library("UpdateBOOTFiles"), 'stopWhenFail',
                    harness.stage_library("RecoverBoard"))

  // Test stage
  def ad9361 = {
    String board ->
    stage("Test libad9361") {
      def ip = nebula('update-config network-config dutip --board-name=' + board)
      retry(3) {
        sleep(5)
        checkout scm
        sh 'git submodule update --init'
      }
      sh 'mkdir build'
      dir('build')
      {
         sh 'cmake .. -DPYTHON_BINDINGS=ON'
         sh 'make'
         sh 'make install'
         sh 'ldconfig'
      }
      try {
          sh 'python3 -m pytest -vs --adi-hw-map --uri=ip:'+ip
      } finally {
          junit testResults: '*.xml', allowEmptyResults: true
      }
    }
  }
  harness.add_stage(ad9361)
  harness.add_stage(harness.stage_library("RestoreIP"), 'stopWhenFail')
  // harness.add_stage(harness.stage_library('SendResults'),'continueWhenFail')

  // // Go go
  harness.run_stages()
}
